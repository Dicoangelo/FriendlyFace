{"id":"friendlyface-5xa","title":"Phase 3: Cryptographic Hardening \u0026 Operational Maturity","description":"Replace stub cryptography with production-grade Ed25519 DIDs (PyNaCl) and Schnorr ZK proofs (numpy-only). Add operational features: SSE event streaming, audit dashboard, portable JSON-LD bundle export/import. Target: ~120 new tests, ~10 new endpoints, zero regressions on existing 725 tests.","status":"open","priority":2,"issue_type":"epic","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:47:14.329148-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T05:50:06.256097-05:00"}
{"id":"friendlyface-5xa.1","title":"US-027: Ed25519 DID:key with PyNaCl","description":"As a platform operator, I want DID:key identifiers backed by real Ed25519 keypairs so that forensic actors have cryptographically verifiable identities.\n\n## Acceptance Criteria\n- [ ] Add `pynacl\u003e=1.5.0` to `pyproject.toml` dependencies\n- [ ] Create `friendlyface/crypto/did.py` with `Ed25519DIDKey` class\n- [ ] `Ed25519DIDKey` generates a real Ed25519 keypair via `nacl.signing.SigningKey`\n- [ ] DID identifier follows `did:key:z6Mk...` format using base58-encoded public key\n- [ ] `resolve()` returns a W3C DID Document with `Ed25519VerificationKey2020` type\n- [ ] `sign(data: bytes) -\u003e bytes` produces a real Ed25519 signature\n- [ ] `verify(data: bytes, signature: bytes) -\u003e bool` verifies against the public key\n- [ ] `export_public() -\u003e bytes` exports the verify key for sharing\n- [ ] `from_seed(seed: bytes)` deterministic key derivation for testing\n- [ ] Backward-compatible: importing `DIDKey` from `friendlyface.stubs.did` still works\n- [ ] Unit tests in `tests/test_ed25519_did.py` covering key generation, signing, verification, DID format, resolve document, deterministic seeds, and invalid signature rejection\n- [ ] Existing `tests/test_did.py` tests still pass (legacy compatibility)\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:47:27.544547-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:16:18.064094-05:00","closed_at":"2026-02-07T08:16:18.064094-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-5xa.1","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:47:27.546052-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.2","title":"US-028: Verifiable Credentials with Ed25519 signatures","description":"As a forensic auditor, I want W3C Verifiable Credentials signed with Ed25519 so that forensic claims are cryptographically tamper-evident.\n\n## Acceptance Criteria\n- [ ] Create `friendlyface/crypto/vc.py` with `VerifiableCredential` class\n- [ ] `issue(claims, credential_type, subject_did)` returns a W3C VC structure with `Ed25519Signature2020` proof type\n- [ ] Proof contains: `type`, `created`, `verificationMethod` (issuer DID), `proofValue` (hex-encoded Ed25519 signature)\n- [ ] `verify(credential, issuer_public_key)` static method verifies the proof signature\n- [ ] Canonical JSON serialization (sorted keys, no whitespace) used for signing\n- [ ] Supports credential types: `ForensicCredential`, `FLParticipantCredential`, `AuditCredential`\n- [ ] Backward-compatible: legacy HMAC VCs (proof starting with `stub::`) accepted by verify with deprecation flag\n- [ ] Unit tests in `tests/test_ed25519_vc.py` covering issuance, verification, tampered credential rejection, legacy stub acceptance, multiple credential types, and round-trip sign/verify\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:47:37.508204-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:21:14.356234-05:00","closed_at":"2026-02-07T13:21:12.833616Z","dependencies":[{"issue_id":"friendlyface-5xa.2","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:47:37.509744-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.2","depends_on_id":"friendlyface-5xa.1","type":"blocks","created_at":"2026-02-07T05:49:29.661832-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.3","title":"US-029: Schnorr ZK proof protocol","description":"As a forensic auditor, I want zero-knowledge proofs based on the Schnorr protocol so that bundle integrity can be verified without revealing bundle contents.\n\n## Acceptance Criteria\n- [ ] Create `friendlyface/crypto/schnorr.py` with numpy-only implementation (no external crypto deps beyond hashlib)\n- [ ] Implement `SchnorrProver` class with: `commit()`, `challenge()`, `respond()`, `generate_proof(secret)`\n- [ ] Implement `SchnorrVerifier` class with: `verify(proof)` returning bool\n- [ ] Proof structure: `{\"scheme\": \"schnorr-sha256\", \"commitment\": hex, \"challenge\": hex, \"response\": hex, \"public_point\": hex}`\n- [ ] Uses SHA-256 for the Fiat-Shamir heuristic (non-interactive variant)\n- [ ] `ZKBundleProver` class wraps Schnorr for bundle-specific proofs: `prove_bundle(bundle_id, bundle_hash) -\u003e proof_str`\n- [ ] `ZKBundleVerifier.verify_bundle(proof_str) -\u003e bool` verifies a bundle proof\n- [ ] Backward-compatible: legacy `zk_stub::` and `pedersen-sha256` proofs still verify as True\n- [ ] Unit tests in `tests/test_schnorr.py` covering proof generation, verification, invalid proof rejection, deterministic challenge (Fiat-Shamir), legacy format acceptance, and multiple sequential proofs\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:47:48.681758-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:16:18.24574-05:00","closed_at":"2026-02-07T08:16:18.24574-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-5xa.3","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:47:48.687437-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.4","title":"US-030: Wire DID + ZK into ForensicBundle lifecycle","description":"As a developer, I want DID credentials and ZK proofs automatically generated during bundle creation so that every bundle is cryptographically anchored.\n\n## Acceptance Criteria\n- [ ] Update `ForensicBundle` model: rename `zk_proof_placeholder` to `zk_proof` and `did_credential_placeholder` to `did_credential` with migration aliases\n- [ ] Update `ForensicService.create_bundle()` to: (1) generate a Schnorr ZK proof over the bundle hash, (2) issue a `ForensicCredential` VC signed by a platform DID key\n- [ ] Platform DID key loaded from `FF_DID_SEED` env var (deterministic) or auto-generated\n- [ ] `ForensicService.verify_bundle()` now also verifies the ZK proof and DID credential\n- [ ] Verification result includes: `zk_valid: bool`, `did_valid: bool`, `credential_issuer: str`\n- [ ] Update SQLite schema: rename columns with `ALTER TABLE` migration in `Database.initialize()`\n- [ ] Update Supabase adapter column names\n- [ ] Existing bundles with `None` or legacy stub values continue to verify\n- [ ] Unit tests in `tests/test_bundle_crypto.py` covering bundle creation with crypto, verification, tampered bundle detection, legacy bundle compatibility, missing env var fallback\n- [ ] Existing `tests/test_bundle_artifacts.py` and `tests/test_integrity.py` still pass\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:00.608238-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:21:14.358478-05:00","closed_at":"2026-02-07T13:21:12.833616Z","dependencies":[{"issue_id":"friendlyface-5xa.4","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:00.609863-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.4","depends_on_id":"friendlyface-5xa.1","type":"blocks","created_at":"2026-02-07T05:49:29.88943-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.4","depends_on_id":"friendlyface-5xa.2","type":"blocks","created_at":"2026-02-07T05:49:30.111727-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.4","depends_on_id":"friendlyface-5xa.3","type":"blocks","created_at":"2026-02-07T05:49:30.337004-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.5","title":"US-031: DID/VC API endpoints","description":"As an API consumer, I want endpoints to create DIDs, issue credentials, and verify credentials so that external systems can participate in the forensic identity layer.\n\n## Acceptance Criteria\n- [ ] `POST /did/create` — Generate a new Ed25519 DID:key, returns `{did, public_key_hex, created_at}`\n- [ ] `GET /did/{did_id}/resolve` — Resolve a DID to its DID Document\n- [ ] `POST /vc/issue` — Issue a VC: accepts `{issuer_did_id, subject_did, claims, credential_type}`, returns the signed VC\n- [ ] `POST /vc/verify` — Verify a VC: accepts `{credential, issuer_public_key_hex}`, returns `{valid: bool, issuer, credential_type}`\n- [ ] DID keys stored in-memory (dict) with optional persistence via forensic events\n- [ ] All endpoints require API key auth (existing `require_api_key` dependency)\n- [ ] Request/response schemas defined as Pydantic models in `app.py`\n- [ ] API integration tests in `tests/test_api.py` (new `TestDID` and `TestVC` classes) covering create, resolve, issue, verify, and error cases\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:12.363685-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:21:14.359169-05:00","closed_at":"2026-02-07T13:21:12.833616Z","dependencies":[{"issue_id":"friendlyface-5xa.5","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:12.364634-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.5","depends_on_id":"friendlyface-5xa.1","type":"blocks","created_at":"2026-02-07T05:49:30.530393-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.5","depends_on_id":"friendlyface-5xa.2","type":"blocks","created_at":"2026-02-07T05:49:30.728451-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.6","title":"US-032: ZK proof API endpoints","description":"As an API consumer, I want endpoints to generate and verify ZK proofs so that external auditors can cryptographically verify bundle integrity.\n\n## Acceptance Criteria\n- [ ] `POST /zk/prove` — Generate a Schnorr proof: accepts `{bundle_id}`, looks up bundle hash, returns proof JSON\n- [ ] `POST /zk/verify` — Verify a proof: accepts `{proof}` JSON string, returns `{valid: bool, scheme, bundle_hash}`\n- [ ] `GET /zk/proofs/{bundle_id}` — Get stored proof for a bundle\n- [ ] Returns 404 if bundle not found\n- [ ] Returns 400 if bundle has no hash (unsealed)\n- [ ] Request/response schemas defined as Pydantic models\n- [ ] API integration tests in `tests/test_api.py` (new `TestZKProof` class) covering prove, verify, stored proof retrieval, not-found, and invalid proof\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:20.338435-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:21:14.359819-05:00","closed_at":"2026-02-07T13:21:12.833616Z","dependencies":[{"issue_id":"friendlyface-5xa.6","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:20.339363-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.6","depends_on_id":"friendlyface-5xa.3","type":"blocks","created_at":"2026-02-07T05:49:30.92775-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.7","title":"US-033: Real-time event streaming via SSE","description":"As a monitoring system, I want to subscribe to a Server-Sent Events stream so that I receive forensic events in real-time as they are recorded.\n\n## Acceptance Criteria\n- [ ] `GET /events/stream` — SSE endpoint returning `text/event-stream` content type\n- [ ] Each forensic event recorded via `ForensicService.record_event()` is broadcast to all connected SSE clients\n- [ ] Event format: `event: forensic_event\\ndata: {JSON}\\n\\n` with event ID, type, actor, timestamp\n- [ ] Implement `EventBroadcaster` class with `subscribe()` / `unsubscribe()` / `broadcast()` using `asyncio.Queue`\n- [ ] Heartbeat: send `event: heartbeat\\ndata: {}\\n\\n` every 15 seconds to keep connections alive\n- [ ] Graceful cleanup: remove client queues on disconnect\n- [ ] Optional `?event_type=inference_result` query parameter to filter by event type\n- [ ] Integration test in `tests/test_api.py` (new `TestSSE` class) covering stream connection, event receipt, heartbeat, and type filtering\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:30.374937-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:16:18.414889-05:00","closed_at":"2026-02-07T08:16:18.414889-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-5xa.7","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:30.376068-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.8","title":"US-034: Audit dashboard endpoint","description":"As a compliance officer, I want a single dashboard endpoint that summarizes platform forensic health so that I can assess system status at a glance.\n\n## Acceptance Criteria\n- [ ] `GET /dashboard` — Returns comprehensive audit dashboard JSON\n- [ ] Response includes: `total_events`, `total_bundles`, `total_provenance_nodes`, `events_by_type` (count per EventType), `recent_events` (last 10), `chain_integrity` (valid/invalid + count), `compliance_summary` (from ComplianceReporter if events exist), `crypto_status` (did_enabled, zk_scheme, total_dids, total_vcs)\n- [ ] `uptime_seconds` and `storage_backend` included\n- [ ] Response cached for 5 seconds to avoid repeated DB queries on rapid polling\n- [ ] Integration test in `tests/test_api.py` (new `TestDashboard` class) covering response structure, event counts after recording, and cache behavior\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:40.945716-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T08:16:18.599569-05:00","closed_at":"2026-02-07T08:16:18.599569-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-5xa.8","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:40.946609-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-5xa.9","title":"US-035: Portable bundle export/import as JSON-LD","description":"As a forensic auditor, I want to export bundles as self-contained JSON-LD documents and import them for independent verification so that forensic evidence is portable across systems.\n\n## Acceptance Criteria\n- [ ] `GET /bundles/{id}/export` — Export a bundle as JSON-LD with `@context` referencing W3C credentials and custom FriendlyFace vocabulary\n- [ ] Exported document includes: all events in the bundle (full ForensicEvent data), Merkle proofs, provenance chain (full nodes), bias audit record, ZK proof, DID credential, and bundle hash\n- [ ] `POST /bundles/import` — Import a JSON-LD bundle document, verify its integrity (hash chain, Merkle proofs, ZK proof, DID credential), and store it\n- [ ] Import verification returns: `{imported: bool, bundle_id, verification: {hash_valid, merkle_valid, zk_valid, did_valid, chain_valid}}`\n- [ ] Import rejects tampered bundles with 422 and detailed error\n- [ ] JSON-LD `@context` includes `https://www.w3.org/2018/credentials/v1` and `https://friendlyface.dev/forensic/v1` (placeholder vocab IRI)\n- [ ] Unit tests in `tests/test_bundle_export.py` covering export structure, round-trip export then import, tampered bundle rejection, missing fields handling\n- [ ] API integration tests in `tests/test_api.py` (new `TestBundleExport` class) covering export endpoint, import endpoint, and verification results\n- [ ] `source .venv/bin/activate \u0026\u0026 pytest tests/ -q \u0026\u0026 ruff check friendlyface/ tests/ \u0026\u0026 ruff format --check friendlyface/ tests/` passes","status":"open","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T05:48:53.427174-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T05:48:53.427174-05:00","dependencies":[{"issue_id":"friendlyface-5xa.9","depends_on_id":"friendlyface-5xa","type":"parent-child","created_at":"2026-02-07T05:48:53.428114-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-5xa.9","depends_on_id":"friendlyface-5xa.4","type":"blocks","created_at":"2026-02-07T05:49:31.130016-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae","title":"FriendlyFace — Forensic-Friendly AI Platform","description":"Full 6-layer forensic-friendly AI facial recognition platform implementing Mohammed's ICDF2C 2024 schema with SOTA 2026 components.\n\nLayers:\n1. Recognition (PCA+SVM)\n2. FL Engine (Flower + poisoning detection)\n3. Blockchain Forensic (MVP COMPLETE)\n4. Fairness Auditor (demographic parity + equalized odds)\n5. Explainability (LIME + SHAP)\n6. Consent \u0026 Governance (EU AI Act readiness)\n\n19 user stories. Quality gates: pytest + ruff.","status":"closed","priority":2,"issue_type":"epic","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:17.491827-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:39.760973-05:00","closed_at":"2026-02-07T02:22:39.760973-05:00","close_reason":"Closed"}
{"id":"friendlyface-fae.1","title":"US-001: Install ruff and configure linting","description":"As a developer, I want ruff configured as the project linter so that code quality is enforced consistently.\n\n## Acceptance Criteria\n- [ ] ruff added to [project.optional-dependencies.dev] in pyproject.toml\n- [ ] [tool.ruff] section configured in pyproject.toml with Python 3.11 target\n- [ ] ruff check friendlyface/ passes with zero errors on existing code\n- [ ] ruff check tests/ passes with zero errors on existing code\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:45.026601-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:01:50.256279-05:00","closed_at":"2026-02-06T13:01:50.256279-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.1","depends_on_id":"friendlyface-fae","type":"parent-child","created_at":"2026-02-06T12:40:45.051543-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.10","title":"US-009: Enhance forensic bundle with full-layer artifacts","description":"As a forensic examiner, I want forensic bundles to include artifacts from all layers (recognition, FL, bias, explainability) so that bundles are comprehensive evidence packages.\n\n## Acceptance Criteria\n- [ ] ForensicBundle model extended with optional fields: recognition_artifacts, fl_artifacts, bias_report, explanation_artifacts\n- [ ] ForensicService.create_bundle() collects artifacts from all available layers\n- [ ] Bundle hash covers all included artifacts\n- [ ] Bundle verification checks integrity of all layer artifacts\n- [ ] API POST /bundles accepts optional layer filters\n- [ ] Integration test: create event chain across layers -\u003e bundle -\u003e verify all artifacts present\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:31.262376-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:23:20.854635-05:00","closed_at":"2026-02-06T14:23:20.854635-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.10","depends_on_id":"friendlyface-fae.8","type":"blocks","created_at":"2026-02-06T12:42:16.22956-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.11","title":"US-011: Bias audit API endpoints and auto-trigger","description":"As a platform operator, I want bias audits to run automatically and be queryable via API so that fairness monitoring is continuous.\n\n## Acceptance Criteria\n- [ ] POST /fairness/audit triggers manual bias audit on specified event range\n- [ ] GET /fairness/audits lists completed audits with summary scores\n- [ ] GET /fairness/audits/{id} full audit details with per-group breakdowns\n- [ ] GET /fairness/status current fairness health (pass/warning/fail)\n- [ ] Auto-audit configurable: trigger after every N recognition events (default: 50)\n- [ ] Integration tests for manual + auto-triggered audits\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:35.746997-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:14:55.552824-05:00","closed_at":"2026-02-06T14:14:55.552824-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.11","depends_on_id":"friendlyface-fae.9","type":"blocks","created_at":"2026-02-06T12:42:15.480263-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.12","title":"US-012: LIME explainability for recognition","description":"As a forensic examiner, I want LIME explanations for each face recognition prediction so that the model reasoning is human-interpretable.\n\n## Acceptance Criteria\n- [ ] friendlyface/explainability/lime_explain.py generates LIME explanations for predictions\n- [ ] Explanation identifies top contributing facial regions (superpixels)\n- [ ] Explanation artifact includes: feature importance map, top-K regions, confidence decomposition\n- [ ] Each explanation logged as ForensicEvent(event_type=EventType.EXPLANATION) with artifact hash\n- [ ] Provenance node created: explanation type linked to inference node\n- [ ] Unit tests verify explanation output structure and forensic logging\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:40.511767-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:54:43.978715-05:00","closed_at":"2026-02-06T13:54:43.978715-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.12","depends_on_id":"friendlyface-fae.3","type":"blocks","created_at":"2026-02-06T12:42:15.667548-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.13","title":"US-015: Consent management system","description":"As a data subject, I want to manage my consent for facial recognition so that my biometric data is only used with explicit permission.\n\n## Acceptance Criteria\n- [ ] friendlyface/governance/consent.py implements consent record management\n- [ ] Consent model: subject_id, purpose, granted (bool), timestamp, expiry, revocation\n- [ ] Consent checked before any recognition inference on a subject\n- [ ] Consent changes logged as ForensicEvent(event_type=EventType.CONSENT_UPDATE)\n- [ ] Revoked consent blocks future inference and logs the block\n- [ ] Storage: consent records in SQLite with full history (no deletes, only appends)\n- [ ] Unit tests for grant, revoke, check, and expiry scenarios\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:44.260273-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:52:24.240209-05:00","closed_at":"2026-02-06T13:52:24.240209-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.13","depends_on_id":"friendlyface-fae.1","type":"blocks","created_at":"2026-02-06T12:42:16.415005-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.14","title":"US-013: SHAP explainability for recognition","description":"As a forensic examiner, I want SHAP explanations as an alternative to LIME so that multiple explanation methods can corroborate findings.\n\n## Acceptance Criteria\n- [ ] friendlyface/explainability/shap_explain.py generates SHAP values for predictions\n- [ ] SHAP values computed per feature dimension\n- [ ] Explanation artifact includes: SHAP values, feature importance ranking, base value\n- [ ] Each explanation logged as ForensicEvent(event_type=EventType.EXPLANATION) with method=shap\n- [ ] Provenance node created linked to same inference node as LIME\n- [ ] Unit tests verify SHAP output and forensic chain\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:45.923479-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:11:36.591873-05:00","closed_at":"2026-02-06T14:11:36.591873-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.14","depends_on_id":"friendlyface-fae.12","type":"blocks","created_at":"2026-02-06T12:42:15.855272-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.15","title":"US-014: Explainability API endpoints","description":"As a developer, I want REST endpoints for generating and retrieving explanations so that explainability is accessible via the API.\n\n## Acceptance Criteria\n- [ ] POST /explain/{event_id} generates LIME + SHAP explanations for an inference event\n- [ ] GET /explanations/{event_id} retrieves all explanations for an event\n- [ ] GET /explanations/{event_id}/{method} retrieves specific method (lime/shap)\n- [ ] Explanations auto-generated with inference if auto_explain=true config\n- [ ] Integration tests for explain -\u003e retrieve -\u003e verify in bundle\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:51.594252-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:39:24.984427-05:00","closed_at":"2026-02-06T14:39:24.984427-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.15","depends_on_id":"friendlyface-fae.14","type":"blocks","created_at":"2026-02-06T12:42:16.046702-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.16","title":"US-016: Governance and compliance reporting","description":"As a compliance officer, I want EU AI Act readiness reports so that the platform compliance posture is documentable.\n\n## Acceptance Criteria\n- [ ] friendlyface/governance/compliance.py generates compliance reports\n- [ ] Report covers: Article 5 (prohibited practices check), Article 14 (human oversight requirements)\n- [ ] Report includes: consent coverage %, bias audit pass rate, explanation coverage %, bundle integrity %\n- [ ] Report output as structured JSON with overall compliance score\n- [ ] Each report generation logged as forensic event\n- [ ] API endpoint GET /governance/compliance returns latest report\n- [ ] API endpoint POST /governance/compliance/generate triggers new report\n- [ ] Unit tests verify report structure and scoring logic\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:53.487623-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:10:22.202456-05:00","closed_at":"2026-02-06T14:10:22.202456-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.16","depends_on_id":"friendlyface-fae.13","type":"blocks","created_at":"2026-02-06T12:42:16.585748-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.17","title":"US-018: Supabase storage adapter","description":"As a developer, I want a Supabase storage backend so that the platform can run in production with managed PostgreSQL.\n\n## Acceptance Criteria\n- [ ] friendlyface/storage/supabase_db.py implements same repository interface as database.py\n- [ ] Uses supabase-py async client\n- [ ] All existing queries translated to Supabase RPC or direct table operations\n- [ ] Storage backend selectable via environment variable FF_STORAGE=sqlite|supabase\n- [ ] Supabase connection configured via SUPABASE_URL and SUPABASE_KEY env vars\n- [ ] Integration tests run against both backends (sqlite by default, supabase when env configured)\n- [ ] Migration SQL file for Supabase table creation\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:55.19577-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:56:00.142819-05:00","closed_at":"2026-02-06T13:56:00.142819-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.17","depends_on_id":"friendlyface-fae.1","type":"blocks","created_at":"2026-02-06T12:42:16.947762-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.18","title":"US-017: Consent and governance API endpoints","description":"As a developer, I want REST endpoints for consent and governance operations so that the full governance layer is API-accessible.\n\n## Acceptance Criteria\n- [ ] POST /consent registers consent (grant or deny) for a subject+purpose\n- [ ] GET /consent/{subject_id} gets all consent records for a subject\n- [ ] DELETE /consent/{subject_id}/{purpose} revokes consent (creates revocation record)\n- [ ] GET /consent/check/{subject_id}/{purpose} checks if consent is active\n- [ ] All consent operations create forensic events\n- [ ] Integration tests for full consent lifecycle\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:42:00.979698-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:21:21.192391-05:00","closed_at":"2026-02-06T14:21:21.192391-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.18","depends_on_id":"friendlyface-fae.16","type":"blocks","created_at":"2026-02-06T12:42:16.769005-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.19","title":"US-019: End-to-end forensic pipeline test","description":"As a QA engineer, I want an end-to-end test that exercises the full forensic pipeline so that cross-layer integrity is verified.\n\n## Acceptance Criteria\n- [ ] tests/test_e2e_pipeline.py tests the complete flow: consent -\u003e train -\u003e recognize -\u003e explain -\u003e audit -\u003e bundle -\u003e verify\n- [ ] Creates 50+ forensic events across all layers\n- [ ] Verifies hash chain integrity across all events\n- [ ] Verifies Merkle proofs for all events\n- [ ] Verifies provenance DAG connectivity (no orphaned nodes)\n- [ ] Verifies bundle contains artifacts from all layers\n- [ ] Verifies tamper detection: modify any event -\u003e bundle verification fails\n- [ ] Test completes in under 30 seconds\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":4,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:42:01.1862-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T14:45:11.55421-05:00","closed_at":"2026-02-06T14:45:11.55421-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.19","depends_on_id":"friendlyface-fae.18","type":"blocks","created_at":"2026-02-06T12:42:17.122762-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.19","depends_on_id":"friendlyface-fae.10","type":"blocks","created_at":"2026-02-06T12:42:17.307903-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.19","depends_on_id":"friendlyface-fae.15","type":"blocks","created_at":"2026-02-06T12:42:17.480616-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.2","title":"US-002: PCA training pipeline","description":"As a forensic analyst, I want to train a PCA dimensionality reduction model on face images so that feature extraction is reproducible and forensically logged.\n\n## Acceptance Criteria\n- [ ] friendlyface/recognition/pca.py implements PCA training using scikit-learn\n- [ ] Accepts a directory of aligned face images (grayscale, 112x112)\n- [ ] Outputs a serialized PCA model (.pkl) with explained variance metadata\n- [ ] Training event logged as ForensicEvent(event_type=EventType.TRAINING) with dataset hash\n- [ ] Provenance node created: training type with dataset source reference\n- [ ] Unit tests verify PCA output dimensions and forensic event creation\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:51.201016-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:07:30.941767-05:00","closed_at":"2026-02-06T13:07:30.941767-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.2","depends_on_id":"friendlyface-fae.1","type":"blocks","created_at":"2026-02-06T12:41:01.989317-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.3","title":"US-004: Face inference pipeline","description":"As a forensic analyst, I want to run face recognition inference so that each prediction is forensically logged with full provenance.\n\n## Acceptance Criteria\n- [ ] friendlyface/recognition/inference.py loads PCA+SVM models and runs prediction\n- [ ] Accepts a single face image, returns top-K matches with confidence scores\n- [ ] Each inference logged as ForensicEvent(event_type=EventType.INFERENCE) with input hash + output\n- [ ] Provenance node created: inference type linked to model node\n- [ ] Merkle tree updated with inference event\n- [ ] API endpoint POST /recognize accepts image upload and returns matches + event_id\n- [ ] Integration test: upload image -\u003e get prediction + verify forensic event exists\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:54.663126-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:19:02.417468-05:00","closed_at":"2026-02-06T13:19:02.417468-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.3","depends_on_id":"friendlyface-fae.4","type":"blocks","created_at":"2026-02-06T12:42:14.314821-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.4","title":"US-003: SVM classifier training pipeline","description":"As a forensic analyst, I want to train an SVM classifier on PCA-reduced features so that face identification has a reproducible baseline model.\n\n## Acceptance Criteria\n- [ ] friendlyface/recognition/svm.py implements SVM training using scikit-learn\n- [ ] Takes PCA-reduced features + labels as input\n- [ ] Outputs serialized SVM model (.pkl) with hyperparameters logged\n- [ ] Training event logged as ForensicEvent(event_type=EventType.TRAINING) with model hash\n- [ ] Provenance node created: model type linked to PCA training node\n- [ ] Cross-validation accuracy reported and stored in event metadata\n- [ ] Unit tests verify model output shape and forensic chain linkage\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:57.699299-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:13:05.951719-05:00","closed_at":"2026-02-06T13:13:05.951719-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.4","depends_on_id":"friendlyface-fae","type":"parent-child","created_at":"2026-02-06T12:40:57.705088-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.4","depends_on_id":"friendlyface-fae.2","type":"blocks","created_at":"2026-02-06T12:41:08.572514-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.5","title":"US-005: Recognition API endpoints","description":"As a developer, I want REST endpoints for training and inference so that the recognition layer is accessible via the API.\n\n## Acceptance Criteria\n- [ ] POST /recognition/train triggers PCA+SVM training on provided dataset path\n- [ ] POST /recognition/predict accepts image, returns top-K matches + forensic event_id\n- [ ] GET /recognition/models lists available trained models with metadata\n- [ ] GET /recognition/models/{id} gets model details including provenance chain\n- [ ] All endpoints return forensic event references\n- [ ] Integration tests for all endpoints\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:40:59.775707-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:29:43.542697-05:00","closed_at":"2026-02-06T13:29:43.542697-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.5","depends_on_id":"friendlyface-fae","type":"parent-child","created_at":"2026-02-06T12:40:59.776885-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.5","depends_on_id":"friendlyface-fae.3","type":"blocks","created_at":"2026-02-06T12:42:14.524199-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.6","title":"US-006: Federated learning simulation engine","description":"As a researcher, I want a simulated federated learning engine so that FL training rounds are forensically logged without requiring distributed infrastructure.\n\n## Acceptance Criteria\n- [ ] friendlyface/fl/engine.py implements simulated FL using Flower simulation mode\n- [ ] Supports configurable number of clients (default: 5)\n- [ ] Each FL round logged as ForensicEvent(event_type=EventType.FL_ROUND) with round metadata\n- [ ] Client updates aggregated via FedAvg strategy\n- [ ] Provenance nodes created per round linking client contributions to aggregated model\n- [ ] Global model hash recorded after each aggregation\n- [ ] Unit tests verify round logging and provenance chain\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:11.583627-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:23:59.355399-05:00","closed_at":"2026-02-06T13:23:59.355399-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.6","depends_on_id":"friendlyface-fae","type":"parent-child","created_at":"2026-02-06T12:41:11.584543-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.6","depends_on_id":"friendlyface-fae.1","type":"blocks","created_at":"2026-02-06T12:42:14.725953-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.7","title":"US-007: Data poisoning detection baseline","description":"As a security researcher, I want basic data poisoning detection during FL rounds so that compromised client updates are flagged forensically.\n\n## Acceptance Criteria\n- [ ] friendlyface/fl/poisoning.py implements norm-based anomaly detection on client updates\n- [ ] Updates exceeding configurable norm threshold are flagged\n- [ ] Flagged updates logged as ForensicEvent(event_type=EventType.SECURITY_ALERT) with details\n- [ ] Poisoning detection results included in FL round provenance\n- [ ] API endpoint GET /fl/rounds/{id}/security returns poisoning detection results\n- [ ] Unit tests with synthetic poisoned updates verify detection and logging\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:16.231354-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:36:27.025945-05:00","closed_at":"2026-02-06T13:36:27.025945-05:00","close_reason":"Completed by agent","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.7","depends_on_id":"friendlyface-fae","type":"parent-child","created_at":"2026-02-06T12:41:16.232554-05:00","created_by":"Dico Angelo"},{"issue_id":"friendlyface-fae.7","depends_on_id":"friendlyface-fae.6","type":"blocks","created_at":"2026-02-06T12:42:14.931728-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.8","title":"US-008: FL API endpoints","description":"As a developer, I want REST endpoints for FL operations so that federated learning is accessible and monitorable.\n\n## Acceptance Criteria\n- [ ] POST /fl/start starts FL simulation with configurable parameters\n- [ ] GET /fl/rounds lists completed FL rounds with summary\n- [ ] GET /fl/rounds/{id} gets round details including client contributions and security status\n- [ ] GET /fl/status returns current FL training status\n- [ ] All endpoints include forensic event references\n- [ ] Integration tests for FL lifecycle (start -\u003e rounds -\u003e completion)\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:26.559577-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:48:36.812859-05:00","closed_at":"2026-02-06T13:48:36.812859-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.8","depends_on_id":"friendlyface-fae.7","type":"blocks","created_at":"2026-02-06T12:42:15.113707-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-fae.9","title":"US-010: Bias audit engine","description":"As a fairness researcher, I want automatic bias auditing on recognition results so that demographic disparities are detected and forensically recorded.\n\n## Acceptance Criteria\n- [ ] friendlyface/fairness/auditor.py computes demographic parity and equalized odds\n- [ ] Accepts recognition results grouped by demographic attribute\n- [ ] Outputs BiasAuditRecord with per-group metrics and overall fairness score\n- [ ] Each audit logged as ForensicEvent(event_type=EventType.BIAS_AUDIT)\n- [ ] Configurable fairness thresholds with automatic alerting\n- [ ] Unit tests with synthetic biased/unbiased data verify metric computation\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 pytest tests/ -v passes\n- [ ] cd ~/friendlyface \u0026\u0026 source .venv/bin/activate \u0026\u0026 ruff check friendlyface/ passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-06T12:41:30.648234-05:00","created_by":"Dico Angelo","updated_at":"2026-02-06T13:51:53.644911-05:00","closed_at":"2026-02-06T13:51:53.644911-05:00","close_reason":"Closed","labels":["ralph"],"dependencies":[{"issue_id":"friendlyface-fae.9","depends_on_id":"friendlyface-fae.5","type":"blocks","created_at":"2026-02-06T12:42:15.305872-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb","title":"Phase 2: Advanced Features","description":"Phase 2 of FriendlyFace: real blockchain integration (ZK proofs, DIDs/VCs), real Flower FL, differential privacy, SDD saliency, multi-modal biometrics, and production hardening.","status":"closed","priority":2,"issue_type":"epic","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:01.386952-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:39.550761-05:00","closed_at":"2026-02-07T02:22:39.550761-05:00","close_reason":"Closed"}
{"id":"friendlyface-jnb.1","title":"US-020: Replace ZK proof stubs with real BioZero implementation","description":"As a forensic examiner, I want real zero-knowledge proofs on forensic bundles so that bundle integrity can be cryptographically verified without revealing contents.\n\n## Acceptance Criteria\n- [ ] Replace stubs/zk.py with real ZK implementation using py_ecc or circom bindings\n- [ ] ForensicBundle.zk_proof_placeholder replaced with actual ZK proof\n- [ ] Bundle verification uses ZK proof validation\n- [ ] Proof generation logged as ForensicEvent\n- [ ] Unit tests for proof generation and verification\n- [ ] pytest passes, ruff passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:10.161062-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:08:34.672824-05:00","closed_at":"2026-02-07T02:08:34.672824-05:00","close_reason":"ZK proofs implemented with Pedersen-SHA256 commitment scheme","dependencies":[{"issue_id":"friendlyface-jnb.1","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:10.163219-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.2","title":"US-021: Replace DID/VC stubs with real decentralized identity","description":"As a platform operator, I want real DID/VC credentials for FL participants so that federated learning has cryptographic accountability per the TBFL pattern.\n\n## Acceptance Criteria\n- [ ] Replace stubs/did.py with real DID:key or DID:web implementation\n- [ ] VCStub replaced with W3C Verifiable Credential issuance\n- [ ] FL round participants identified by DIDs\n- [ ] Credential verification integrated into forensic bundle\n- [ ] Unit tests for DID resolution and VC verification\n- [ ] pytest passes, ruff passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:40.420401-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:08:34.825991-05:00","closed_at":"2026-02-07T02:08:34.825991-05:00","close_reason":"DID:key and W3C Verifiable Credentials implemented with HMAC proofs","dependencies":[{"issue_id":"friendlyface-jnb.2","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:40.421769-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.3","title":"US-022: Real Flower federated learning engine","description":"As a researcher, I want real Flower FL training instead of Gaussian noise simulation so that FL rounds produce actual model improvements.\n\n## Acceptance Criteria\n- [ ] Replace simulated SGD with real Flower client/server using flwr library\n- [ ] Support configurable number of FL clients with real data partitions\n- [ ] FedAvg strategy with actual gradient aggregation\n- [ ] Preserve all forensic event logging (FL_ROUND events)\n- [ ] Poisoning detection works on real gradient norms\n- [ ] Integration test with synthetic face data\n- [ ] pytest passes, ruff passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:40.625859-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:15.939263-05:00","closed_at":"2026-02-07T02:22:15.939263-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-jnb.3","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:40.626866-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.4","title":"US-023: Differential privacy for FL rounds","description":"As a privacy researcher, I want differential privacy applied during FL training so that individual training data cannot be reconstructed from model updates.\n\n## Acceptance Criteria\n- [ ] Implement DP-SGD or FedFDP gradient clipping per arXiv:2402.16028\n- [ ] Configurable epsilon/delta privacy budget\n- [ ] Privacy budget tracked per FL simulation\n- [ ] Each round logs privacy_spent in ForensicEvent metadata\n- [ ] Fairness-aware clipping (demographic groups get proportional noise)\n- [ ] pytest passes, ruff passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:40.840358-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:19.390719-05:00","closed_at":"2026-02-07T02:22:19.390719-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-jnb.4","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:40.84125-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.5","title":"US-024: SDD saliency maps for explainability","description":"As a forensic examiner, I want SDD saliency maps per arXiv:2505.03837 so that face recognition explanations highlight specific facial regions used for identification.\n\n## Acceptance Criteria\n- [ ] Implement SDD saliency computation in explainability/sdd_explain.py\n- [ ] Saliency map shows pixel-level contribution to recognition decision\n- [ ] API endpoint POST /explainability/sdd generates SDD explanation\n- [ ] Comparison endpoint updated to include SDD alongside LIME and SHAP\n- [ ] Forensic event logged with saliency artifact hash\n- [ ] pytest passes, ruff passes","status":"closed","priority":2,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:41.050359-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:19.595068-05:00","closed_at":"2026-02-07T02:22:19.595068-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-jnb.5","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:41.071537-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.6","title":"US-025: Multi-modal biometrics (voice + face fusion)","description":"As a forensic analyst, I want multi-modal biometric fusion (face + voice) so that recognition has higher confidence through corroborating evidence per FAME 2026.\n\n## Acceptance Criteria\n- [ ] Add recognition/voice.py for voice embedding extraction\n- [ ] Implement score-level fusion (weighted combination of face + voice scores)\n- [ ] API endpoint POST /recognition/multimodal accepts image + audio\n- [ ] Fusion result logged as ForensicEvent with per-modality scores\n- [ ] Provenance node links both modality inference nodes\n- [ ] pytest passes, ruff passes","status":"closed","priority":3,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:41.280157-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:22:19.793432-05:00","closed_at":"2026-02-07T02:22:19.793432-05:00","close_reason":"Closed","dependencies":[{"issue_id":"friendlyface-jnb.6","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:41.281429-05:00","created_by":"Dico Angelo"}]}
{"id":"friendlyface-jnb.7","title":"US-026: Production hardening (rate limiting, CORS, logging)","description":"As a platform operator, I want production-grade API hardening so that the deployed service is secure and observable.\n\n## Acceptance Criteria\n- [ ] Add slowapi rate limiting (configurable per endpoint)\n- [ ] Add CORS middleware with configurable origins\n- [ ] Add structured JSON logging (request ID, latency, status)\n- [ ] Add request validation middleware (payload size limits)\n- [ ] Health endpoint includes uptime, version, DB stats\n- [ ] pytest passes, ruff passes","status":"closed","priority":1,"issue_type":"task","owner":"dicoangelo@blackamethystcapitalkeyhold.onmicrosoft.com","created_at":"2026-02-07T02:03:41.483972-05:00","created_by":"Dico Angelo","updated_at":"2026-02-07T02:08:34.512796-05:00","closed_at":"2026-02-07T02:08:34.512796-05:00","close_reason":"Production hardening implemented: CORS, request logging, enhanced health endpoint","dependencies":[{"issue_id":"friendlyface-jnb.7","depends_on_id":"friendlyface-jnb","type":"parent-child","created_at":"2026-02-07T02:03:41.485497-05:00","created_by":"Dico Angelo"}]}
